{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ClassifAbeilles.ipynb","provenance":[],"collapsed_sections":["xzZYwhV0Iaww","T8wS3HAynMlY","CN1hk3SeoEYJ","h6MijFSSqNEi","wHrwHiS3Szq3","34MnJ8YHqXKC","HYD4k8GDtG-G","AGrRfh4ZrHM1"],"authorship_tag":"ABX9TyPWAJ28hjh3VB4RHipSfk+k"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["<h1> Classification d'abeilles </h1>\n","\n"],"metadata":{"id":"2pMcPEIkmnVU"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MorcXQTb22HG","outputId":"997a4015-4e21-4ce9-d9a7-6af7ba61c808","executionInfo":{"status":"ok","timestamp":1658840260371,"user_tz":-120,"elapsed":15008,"user":{"displayName":"Boshi","userId":"08165065872120645038"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["## Téléchargement de la base de données"],"metadata":{"id":"xzZYwhV0Iaww"}},{"cell_type":"code","source":["import tensorflow as tf"],"metadata":{"id":"7AoxedDPm5Bu","executionInfo":{"status":"ok","timestamp":1658842417221,"user_tz":-120,"elapsed":229,"user":{"displayName":"Boshi","userId":"08165065872120645038"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"5b109c85-fe97-4aff-ee95-5924660eceb7","executionInfo":{"status":"ok","timestamp":1658842417706,"user_tz":-120,"elapsed":233,"user":{"displayName":"Boshi","userId":"08165065872120645038"}},"id":"pjqqzJcoIh-_"},"outputs":[{"output_type":"stream","name":"stdout","text":["fatal: destination path 'abeilles-cap500' already exists and is not an empty directory.\n"]}],"source":["!git clone https://github.com/fabiopereira59/abeilles-cap500"]},{"cell_type":"code","source":["IMG_SIZE = 224\n","train_ds = tf.keras.utils.image_dataset_from_directory(\n","    directory='abeilles-cap500/train/',\n","    labels='inferred',\n","    label_mode='categorical',\n","    shuffle = False,\n","    batch_size=16,\n","    image_size=(IMG_SIZE, IMG_SIZE))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"7dd95317-c6ba-4442-961c-a457133d7d49","executionInfo":{"status":"ok","timestamp":1658842418749,"user_tz":-120,"elapsed":1046,"user":{"displayName":"Boshi","userId":"08165065872120645038"}},"id":"I7Di5BLCIh-_"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 14917 files belonging to 71 classes.\n"]}]},{"cell_type":"code","source":["class_names = train_ds.class_names\n","print(class_names)\n","nb_classes = len(class_names)\n","print(nb_classes)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b2d52dcc-a61e-49cd-c35b-8538f58c17bc","executionInfo":{"status":"ok","timestamp":1658842418750,"user_tz":-120,"elapsed":8,"user":{"displayName":"Boshi","userId":"08165065872120645038"}},"id":"VgrOKSfaIh-_"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["['Amegilla quadrifasciata', 'Andrena agilissima', 'Andrena bicolor', 'Andrena cineraria', 'Andrena clarkella', 'Andrena denticulata', 'Andrena flavipes', 'Andrena florea', 'Andrena fulva', 'Andrena gravida', 'Andrena haemorrhoa', 'Andrena hattorfiana', 'Andrena nigroaenea', 'Andrena nitida', 'Andrena nycthemera', 'Andrena thoracica', 'Andrena vaga', 'Andrena ventralis', 'Anthidiellum strigatum', 'Anthidium florentinum', 'Anthidium manicatum', 'Anthidium oblongatum', 'Anthidium septemspinosum', 'Anthophora bimaculata', 'Anthophora furcata', 'Anthophora plumipes', 'Apis mellifera', 'Bombus argillaceus', 'Bombus bohemicus', 'Bombus campestris', 'Bombus hortorum', 'Bombus humilis', 'Bombus hypnorum', 'Bombus lapidarius', 'Bombus lucorum', 'Bombus muscorum', 'Bombus pascuorum', 'Bombus pratorum', 'Bombus ruderatus', 'Bombus rupestris', 'Bombus sylvarum', 'Bombus terrestris lusitanicus', 'Bombus vestalis', 'Ceratina cucurbitina', 'Chelostoma florisomne', 'Colletes cunicularius', 'Colletes hederae', 'Dasypoda hirtipes', 'Halictus rubicundus', 'Halictus scabiosae', 'Halictus sexcinctus', 'Heriades truncorum', 'Hylaeus variegatus', 'Lithurgus chrysurus', 'Macropis europaea', 'Megachile centuncularis', 'Megachile ericetorum', 'Megachile sculpturalis', 'Melecta albifrons', 'Nomada goodeniana', 'Nomada lathburiana', 'Osmia aurulenta', 'Osmia bicolor', 'Osmia bicornis', 'Osmia caerulescens', 'Osmia cornuta', 'Rhodanthidium septemdentatum', 'Rhodanthidium sticticum', 'Sphecodes albilabris', 'Xylocopa valga', 'Xylocopa violacea']\n","71\n"]}]},{"cell_type":"markdown","source":["## Chargement des données"],"metadata":{"id":"T8wS3HAynMlY"}},{"cell_type":"code","source":["from tensorflow import keras\n","from tensorflow.keras import layers"],"metadata":{"id":"FR4iw29DI1V_","executionInfo":{"status":"ok","timestamp":1658842446314,"user_tz":-120,"elapsed":249,"user":{"displayName":"Boshi","userId":"08165065872120645038"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["# Paramètres\n","IMG_SIZE = 224 # pour utiliser ResNet"],"metadata":{"id":"4jXjNBybI1V_","executionInfo":{"status":"ok","timestamp":1658842446586,"user_tz":-120,"elapsed":6,"user":{"displayName":"Boshi","userId":"08165065872120645038"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"8ca05ddc-6308-47e6-91c2-d82cb8ca9ebe","executionInfo":{"status":"ok","timestamp":1658842447622,"user_tz":-120,"elapsed":1041,"user":{"displayName":"Boshi","userId":"08165065872120645038"}},"id":"I_nea1RwI1V_"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 14917 files belonging to 71 classes.\n","Found 1832 files belonging to 71 classes.\n"]}],"source":["# Récupération des dataset pour l'entraînement (train, val)\n","# Shuffle à false pour avoir accès aux images depuis\n","# leur chemin d'accès avec train_ds.file_paths\n","train_ds = keras.utils.image_dataset_from_directory(\n","    directory='abeilles-cap500/train/',\n","    labels='inferred',\n","    label_mode='categorical',\n","    shuffle = False,\n","    batch_size=16,\n","    image_size=(IMG_SIZE, IMG_SIZE))\n","\n","validation_ds = keras.utils.image_dataset_from_directory(\n","    directory='abeilles-cap500/val/',\n","    labels='inferred',\n","    label_mode='categorical',\n","    batch_size=16,\n","    image_size=(IMG_SIZE, IMG_SIZE))"]},{"cell_type":"markdown","source":["## Augmentation de données : Sequence et Albumentations"],"metadata":{"id":"CN1hk3SeoEYJ"}},{"cell_type":"code","source":["!pip uninstall opencv-python-headless==4.5.5.62\n","!pip install opencv-python-headless==4.1.2.30\n","!pip install -q -U albumentations\n","!echo \"$(pip freeze | grep albumentations) is successfully installed\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":729},"id":"-WvZXN580RYP","outputId":"c774cb1e-156d-48a6-e6f6-97bcc6c0b2ab","executionInfo":{"status":"ok","timestamp":1658842474363,"user_tz":-120,"elapsed":22321,"user":{"displayName":"Boshi","userId":"08165065872120645038"}}},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["Found existing installation: opencv-python-headless 4.1.2.30\n","Uninstalling opencv-python-headless-4.1.2.30:\n","  Would remove:\n","    /usr/local/lib/python3.7/dist-packages/cv2/*\n","    /usr/local/lib/python3.7/dist-packages/opencv_python_headless-4.1.2.30.dist-info/*\n","  Would not remove (might be manually added):\n","    /usr/local/lib/python3.7/dist-packages/cv2/config-3.py\n","    /usr/local/lib/python3.7/dist-packages/cv2/config.py\n","    /usr/local/lib/python3.7/dist-packages/cv2/cv2.abi3.so\n","    /usr/local/lib/python3.7/dist-packages/cv2/gapi/__init__.py\n","    /usr/local/lib/python3.7/dist-packages/cv2/load_config_py2.py\n","    /usr/local/lib/python3.7/dist-packages/cv2/load_config_py3.py\n","    /usr/local/lib/python3.7/dist-packages/cv2/mat_wrapper/__init__.py\n","    /usr/local/lib/python3.7/dist-packages/cv2/misc/__init__.py\n","    /usr/local/lib/python3.7/dist-packages/cv2/misc/version.py\n","    /usr/local/lib/python3.7/dist-packages/cv2/qt/fonts/DejaVuSans-Bold.ttf\n","    /usr/local/lib/python3.7/dist-packages/cv2/qt/fonts/DejaVuSans-BoldOblique.ttf\n","    /usr/local/lib/python3.7/dist-packages/cv2/qt/fonts/DejaVuSans-ExtraLight.ttf\n","    /usr/local/lib/python3.7/dist-packages/cv2/qt/fonts/DejaVuSans-Oblique.ttf\n","    /usr/local/lib/python3.7/dist-packages/cv2/qt/fonts/DejaVuSans.ttf\n","    /usr/local/lib/python3.7/dist-packages/cv2/qt/fonts/DejaVuSansCondensed-Bold.ttf\n","    /usr/local/lib/python3.7/dist-packages/cv2/qt/fonts/DejaVuSansCondensed-BoldOblique.ttf\n","    /usr/local/lib/python3.7/dist-packages/cv2/qt/fonts/DejaVuSansCondensed-Oblique.ttf\n","    /usr/local/lib/python3.7/dist-packages/cv2/qt/fonts/DejaVuSansCondensed.ttf\n","    /usr/local/lib/python3.7/dist-packages/cv2/qt/plugins/platforms/libqxcb.so\n","    /usr/local/lib/python3.7/dist-packages/cv2/utils/__init__.py\n","    /usr/local/lib/python3.7/dist-packages/cv2/version.py\n","Proceed (y/n)? y\n","  Successfully uninstalled opencv-python-headless-4.1.2.30\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting opencv-python-headless==4.1.2.30\n","  Using cached opencv_python_headless-4.1.2.30-cp37-cp37m-manylinux1_x86_64.whl (21.8 MB)\n","Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python-headless==4.1.2.30) (1.21.6)\n","Installing collected packages: opencv-python-headless\n","Successfully installed opencv-python-headless-4.1.2.30\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["cv2"]}}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["albumentations==1.2.1 is successfully installed\n"]}]},{"cell_type":"code","source":["from albumentations import (Compose, Rotate, HorizontalFlip, VerticalFlip, Affine, RandomBrightnessContrast, ChannelShuffle)\n","import albumentations as A\n","\n","AUGMENTATIONS_TRAIN = Compose([\n","    Rotate(limit=[0,100], p=0.5),\n","    HorizontalFlip(p=0.5),\n","    VerticalFlip(p=0.5),\n","    Affine(shear=[-45, 45], p=0.5),\n","    RandomBrightnessContrast(p=0.5)\n","])"],"metadata":{"id":"G1H0ApCB35Gn","executionInfo":{"status":"ok","timestamp":1658842520255,"user_tz":-120,"elapsed":11,"user":{"displayName":"Boshi","userId":"08165065872120645038"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.utils import Sequence\n","import numpy as np\n","import cv2 as cv\n","\n","class AbeillesSequence(Sequence):\n","    # Initialisation de la séquence avec différents paramètres\n","    def __init__(self, x_train, y_train, batch_size, augmentations):\n","        self.x_train = x_train\n","        self.y_train = y_train\n","        self.classes = class_names\n","        self.batch_size = batch_size\n","        self.augment = augmentations\n","        self.indices1 = np.arange(len(x_train))\n","        np.random.shuffle(self.indices1) # Les indices permettent d'accéder\n","        # aux données et sont randomisés à chaque epoch pour varier la composition\n","        # des batches au cours de l'entraînement\n","\n","    # Fonction calculant le nombre de pas de descente du gradient par epoch\n","    def __len__(self):\n","        return int(np.ceil(x_train.shape[0] / float(self.batch_size)))\n","    \n","    # Application de l'augmentation de données à chaque image du batch\n","    def apply_augmentation(self, bx, by):\n","\n","        batch_x = np.zeros((bx.shape[0], IMG_SIZE, IMG_SIZE, 3))\n","        batch_y = by\n","        \n","        # Pour chaque image du batch\n","        for i in range(len(bx)):\n","            class_labels = []\n","            class_id = np.argmax(by[i])\n","            class_labels.append(self.classes[class_id])\n","\n","            # Application de l'augmentation à l'image\n","            img = cv.imread(bx[i])\n","            img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n","            transformed = self.augment(image=img)\n","            batch_x[i] = transformed['image']\n","      \n","        return batch_x, batch_y\n","\n","    # Fonction appelée à chaque nouveau batch : sélection et augmentation des données\n","    # idx = position du batch (idx = 5 => on prend le 5ème batch)\n","    def __getitem__(self, idx):\n","        batch_x = self.x_train[self.indices1[idx * self.batch_size:(idx + 1) * self.batch_size]]\n","        batch_y = self.y_train[self.indices1[idx * self.batch_size:(idx + 1) * self.batch_size]]\n","           \n","        batch_x, batch_y = self.apply_augmentation(batch_x, batch_y)\n","\n","        # Normalisation des données\n","        batch_x = tf.keras.applications.resnet.preprocess_input(batch_x)\n","        \n","        return batch_x, batch_y\n","\n","    # Fonction appelée à la fin d'un epoch ; on randomise les indices d'accès aux données\n","    def on_epoch_end(self):\n","        np.random.shuffle(self.indices1)"],"metadata":{"id":"tEaycO8VhyLH","executionInfo":{"status":"ok","timestamp":1658842630318,"user_tz":-120,"elapsed":216,"user":{"displayName":"Boshi","userId":"08165065872120645038"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["# Les images sont stockées avec les chemins d'accès\n","import numpy as np\n","\n","x_train = np.array(train_ds.file_paths)\n","y_train = np.zeros((14917, nb_classes))\n","\n","ind_data = 0\n","for bx, by in train_ds.as_numpy_iterator():\n","  y_train[ind_data:ind_data+bx.shape[0]] = by\n","  ind_data += bx.shape[0]"],"metadata":{"id":"MQxHTeedPwsn","executionInfo":{"status":"ok","timestamp":1658842645801,"user_tz":-120,"elapsed":12892,"user":{"displayName":"Boshi","userId":"08165065872120645038"}}},"execution_count":38,"outputs":[]},{"cell_type":"code","source":["# Instanciation de la Sequence\n","train_ds_aug = AbeillesSequence(x_train, y_train, batch_size=16, augmentations=AUGMENTATIONS_TRAIN)\n","\n","# Normalisation des données de validation\n","import numpy as np\n","import tensorflow as tf\n","\n","x_val = np.zeros((1832, IMG_SIZE, IMG_SIZE, 3))\n","y_val = np.zeros((1832, nb_classes))\n","\n","ind_data = 0\n","for bx, by in validation_ds.as_numpy_iterator():\n","  x_val[ind_data:ind_data+bx.shape[0]] = bx\n","  y_val[ind_data:ind_data+bx.shape[0]] = by\n","  ind_data += bx.shape[0]\n","\n","x_val = tf.keras.applications.resnet.preprocess_input(x_val)"],"metadata":{"id":"qclVcaJrG1Gn","executionInfo":{"status":"ok","timestamp":1658842649588,"user_tz":-120,"elapsed":3795,"user":{"displayName":"Boshi","userId":"08165065872120645038"}}},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":["## Création du modèle"],"metadata":{"id":"h6MijFSSqNEi"}},{"cell_type":"code","source":["from tensorflow.keras import regularizers\n","from tensorflow.keras import optimizers\n","import tensorflow as tf"],"metadata":{"id":"vw8pjRnlGcOW","executionInfo":{"status":"ok","timestamp":1658842655320,"user_tz":-120,"elapsed":251,"user":{"displayName":"Boshi","userId":"08165065872120645038"}}},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":["### Poids d'imagenet"],"metadata":{"id":"wHrwHiS3Szq3"}},{"cell_type":"code","source":["conv_base = keras.applications.resnet.ResNet101(\n","    include_top=False,\n","    weights='imagenet',\n","    input_tensor=None,\n","    input_shape=(IMG_SIZE, IMG_SIZE, 3),\n","    pooling=None,\n","    classes=nb_classes,\n",")\n","\n","model = keras.Sequential(\n","    [\n","        conv_base,\n","        layers.GlobalAveragePooling2D(),\n","        layers.Dense(nb_classes, kernel_regularizer=regularizers.L2(1e-4), activation='softmax')\n","    ]\n",")"],"metadata":{"id":"cVEsReLqsmGX","executionInfo":{"status":"ok","timestamp":1658842661739,"user_tz":-120,"elapsed":4453,"user":{"displayName":"Boshi","userId":"08165065872120645038"}}},"execution_count":41,"outputs":[]},{"cell_type":"code","source":["model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8Ouz5O07S8q3","executionInfo":{"status":"ok","timestamp":1658842661740,"user_tz":-120,"elapsed":19,"user":{"displayName":"Boshi","userId":"08165065872120645038"}},"outputId":"b8c82afd-4776-4006-fe62-07a652e7bfde"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," resnet101 (Functional)      (None, 7, 7, 2048)        42658176  \n","                                                                 \n"," global_average_pooling2d_2   (None, 2048)             0         \n"," (GlobalAveragePooling2D)                                        \n","                                                                 \n"," dense_1 (Dense)             (None, 71)                145479    \n","                                                                 \n","=================================================================\n","Total params: 42,803,655\n","Trainable params: 42,698,311\n","Non-trainable params: 105,344\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["### Poids INat2021"],"metadata":{"id":"34MnJ8YHqXKC"}},{"cell_type":"code","source":["from tensorflow import keras\n","conv_base = keras.models.load_model('drive/MyDrive/Stage2A/INat2021/2623871_resnet50_simclr_v1_inat20_no_top.h5')\n","\n","model = keras.Sequential(\n","    [\n","        conv_base,\n","        layers.Dense(nb_classes, kernel_regularizer=regularizers.L2(1e-4), activation='softmax')\n","    ]\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658475118412,"user_tz":-120,"elapsed":5731,"user":{"displayName":"Boshi","userId":"08165065872120645038"}},"outputId":"984ac58b-baa3-4228-876f-42bfb539af62","id":"LR4GIHqVqXKC"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"]}]},{"cell_type":"code","source":["model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658475126907,"user_tz":-120,"elapsed":10,"user":{"displayName":"Boshi","userId":"08165065872120645038"}},"outputId":"bc14d7c3-074d-45d0-b798-bd78536f4ab1","id":"w5wZDTlHqXKD"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," resnet101 (Functional)      (None, 7, 7, 2048)        42658176  \n","                                                                 \n"," global_average_pooling2d_1   (None, 2048)             0         \n"," (GlobalAveragePooling2D)                                        \n","                                                                 \n"," dense_2 (Dense)             (None, 71)                145479    \n","                                                                 \n","=================================================================\n","Total params: 42,803,655\n","Trainable params: 42,698,311\n","Non-trainable params: 105,344\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["## Hierarchical loss"],"metadata":{"id":"HYD4k8GDtG-G"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","\n","hierarchie = pd.read_csv(\"/content/drive/MyDrive/Stage2A/hierarchie_especes71.csv\")\n","\n","species = hierarchie[\"species\"].unique()\n","nb_species = len(species)\n","\n","genus = list(hierarchie[\"genus\"].unique())\n","nb_genus = len(genus)\n","\n","family = list(hierarchie[\"family\"].unique())\n","nb_family = len(family)\n","\n","subfamily = list(hierarchie[\"subfamily\"].unique())\n","nb_subfamily = len(subfamily)\n","\n","#hierarchie.set_index(\"species\", inplace=True)\n","data = pd.read_csv(\"/content/drive/MyDrive/Stage2A/liste_classes_71.csv\")\n","#data.set_index(\"species\", inplace=True)\n","\n","species_to_genus = np.zeros((nb_genus, nb_species))\n","genus_to_subfamily = np.zeros((nb_subfamily, nb_genus))\n","subfamily_to_family = np.zeros((nb_family, nb_subfamily))\n","for i in range(nb_species):\n","  nb_images = data.at[i, \"0\"]\n","  # species -> genus\n","  genus_species = hierarchie.at[i, \"genus\"]\n","  ind_genus = genus.index(genus_species)\n","  species_to_genus[ind_genus, i] = 1\n","\n","  # genus -> subfamily\n","  subfamily_species = hierarchie.at[i, \"subfamily\"]\n","  ind_subfamily = subfamily.index(subfamily_species)\n","  genus_to_subfamily[ind_subfamily, ind_genus] = 1\n","\n","  # subfamily -> family\n","  family_species = hierarchie.at[i, \"family\"]\n","  ind_family = family.index(family_species)\n","  subfamily_to_family[ind_family, ind_subfamily] = 1"],"metadata":{"id":"vHFsiNjctJsM","executionInfo":{"status":"ok","timestamp":1658842675647,"user_tz":-120,"elapsed":852,"user":{"displayName":"Boshi","userId":"08165065872120645038"}}},"execution_count":43,"outputs":[]},{"cell_type":"code","source":["from numpy.ma.core import transpose\n","from keras import backend as K\n","import math\n","import tensorflow as tf\n","\n","# Définition de la fonction de perte\n","def Hierarchicaloss(species_to_genus, genus_to_subfamily, subfamily_to_family, batch_size, alpha=0.1):\n","\n","    def weight(height=1):\n","      return math.exp(-alpha * height)\n","    \n","    def species_loss(y_true, y_pred):\n","      height = 0\n","      return weight(height) * K.categorical_crossentropy(y_true, y_pred)\n","  \n","    def species_to_genus_loss(y_true, y_pred):\n","      height = 1\n","      y_true_genus = K.transpose(tf.raw_ops.MatMul(a=species_to_genus, b=tf.cast(y_true, tf.float64), transpose_b=True))\n","      y_pred_genus = K.transpose(tf.raw_ops.MatMul(a=species_to_genus, b=tf.cast(y_pred, tf.float64), transpose_b=True))\n","      return weight(height) * K.categorical_crossentropy(y_true_genus, y_pred_genus), y_true_genus, y_pred_genus\n","    \n","    def genus_to_subfamily_loss(y_true, y_pred):\n","      height = 2\n","      y_true_subfamily = K.transpose(tf.raw_ops.MatMul(a=genus_to_subfamily, b=y_true, transpose_b=True))\n","      y_pred_subfamily = K.transpose(tf.raw_ops.MatMul(a=genus_to_subfamily, b=y_pred, transpose_b=True))\n","      return weight(height) * K.categorical_crossentropy(y_true_subfamily, y_pred_subfamily), y_true_subfamily, y_pred_subfamily\n","    \n","    def subfamily_to_family_loss(y_true, y_pred):\n","      height = 3\n","      y_true_family = K.transpose(tf.raw_ops.MatMul(a=subfamily_to_family, b=y_true, transpose_b=True))\n","      y_pred_family = K.transpose(tf.raw_ops.MatMul(a=subfamily_to_family, b=y_pred, transpose_b=True))\n","      return weight(height) * K.categorical_crossentropy(y_true_family, y_pred_family)\n","\n","    def HIERARCHICAL_loss(y_true, y_pred):\n","      loss_species = tf.cast(species_loss(y_true, y_pred), tf.float64)\n","      loss_genus, y_true_genus, y_pred_genus = species_to_genus_loss(y_true, y_pred)\n","      loss_subfamily, y_true_subfamily, y_pred_subfamily = genus_to_subfamily_loss(y_true_genus, y_pred_genus)\n","      loss_family = subfamily_to_family_loss(y_true_subfamily, y_pred_subfamily)\n","      return (loss_species + loss_genus + loss_subfamily + loss_family)/batch_size\n","   \n","    # Return a function\n","    return HIERARCHICAL_loss"],"metadata":{"id":"tAmdf0ELtSUr","executionInfo":{"status":"ok","timestamp":1658842675648,"user_tz":-120,"elapsed":5,"user":{"displayName":"Boshi","userId":"08165065872120645038"}}},"execution_count":44,"outputs":[]},{"cell_type":"code","source":["loss=[Hierarchicaloss(species_to_genus, genus_to_subfamily, subfamily_to_family, batch_size=16, alpha=0.5)]"],"metadata":{"id":"MEDUO4smtiAS","executionInfo":{"status":"ok","timestamp":1658842675649,"user_tz":-120,"elapsed":5,"user":{"displayName":"Boshi","userId":"08165065872120645038"}}},"execution_count":45,"outputs":[]},{"cell_type":"markdown","source":["## Entraînement du modèle"],"metadata":{"id":"AGrRfh4ZrHM1"}},{"cell_type":"code","source":["# Ajout de l'optimiseur, de la fonction coût et des métriques\n","lr = 1e-3\n","model.compile(optimizers.SGD(learning_rate=lr, momentum=0.9), loss=loss, metrics=['categorical_accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])"],"metadata":{"id":"IOxq6KpzGb9I","executionInfo":{"status":"ok","timestamp":1658842682265,"user_tz":-120,"elapsed":225,"user":{"displayName":"Boshi","userId":"08165065872120645038"}}},"execution_count":46,"outputs":[]},{"cell_type":"code","source":["# Les callbacks\n","model_checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n","    filepath='./drive/MyDrive/Stage2A/cap500/ResNet101/ResNet101_HierarchicalLossScheduler/Poids/best_model_scheduler',\n","    save_weights_only=True,\n","    monitor='val_categorical_accuracy',\n","    mode='max',\n","    save_best_only=True,\n","    verbose=1)\n","\n","#early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n","#    monitor=\"val_categorical_accuracy\",\n","#    min_delta=0.01,\n","#    patience=8,\n","#    verbose=1,\n","#    mode=\"auto\")\n","reduce_lr_cb = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_categorical_accuracy', factor=0.1,\n","                              patience=5, min_lr=0.00001, verbose=1)"],"metadata":{"id":"tWhbz7V0Gtjs","executionInfo":{"status":"ok","timestamp":1658842683474,"user_tz":-120,"elapsed":4,"user":{"displayName":"Boshi","userId":"08165065872120645038"}}},"execution_count":47,"outputs":[]},{"cell_type":"code","source":["history = model.fit(train_ds_aug, epochs=150, validation_data = (x_val, y_val), callbacks=[model_checkpoint_cb, reduce_lr_cb])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":347},"id":"0hxLaoBeGxTn","outputId":"c04250de-bd71-4292-8434-629bf8ae1fa1","executionInfo":{"status":"error","timestamp":1658842814895,"user_tz":-120,"elapsed":129103,"user":{"displayName":"Boshi","userId":"08165065872120645038"}}},"execution_count":48,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/150\n","  6/933 [..............................] - ETA: 4:17:26 - loss: 0.4709 - categorical_accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-48-632e65f2cba3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds_aug\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_checkpoint_cb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_lr_cb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}]}